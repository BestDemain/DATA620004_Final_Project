#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯„ä¼°å·¥å…·æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æµ‹è¯•é›†åˆ’åˆ†å’Œè¯„ä¼°å·¥å…·
"""

import os
import sys
import json
from pathlib import Path

def demo_test_split():
    """æ¼”ç¤ºæµ‹è¯•é›†åˆ’åˆ†åŠŸèƒ½"""
    print("=" * 60)
    print("æ¼”ç¤ºï¼šæµ‹è¯•é›†åˆ’åˆ†")
    print("=" * 60)
    
    data_path = Path("./data")
    
    # æ£€æŸ¥æ•°æ®
    images_path = data_path / "images"
    if not images_path.exists():
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°å›¾åƒæ–‡ä»¶å¤¹ {images_path}")
        return False
    
    # ç»Ÿè®¡å›¾åƒæ•°é‡
    image_files = list(images_path.glob("*.jpg")) + list(images_path.glob("*.png"))
    print(f"å‘çŽ° {len(image_files)} å¼ å›¾åƒ")
    
    # æ£€æŸ¥æµ‹è¯•é›†æ–‡ä»¶
    test_file = data_path / "sparse" / "0" / "test.txt"
    if test_file.exists():
        with open(test_file, 'r') as f:
            test_images = [line.strip() for line in f if line.strip()]
        
        print(f"\nå½“å‰æµ‹è¯•é›†åŒ…å« {len(test_images)} å¼ å›¾åƒï¼š")
        for img in test_images:
            print(f"  - {img}")
        
        print(f"\næµ‹è¯•é›†æ¯”ä¾‹: {len(test_images)/len(image_files)*100:.1f}%")
        print(f"è®­ç»ƒé›†å›¾åƒæ•°é‡: {len(image_files) - len(test_images)}")
    else:
        print("\næµ‹è¯•é›†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤åˆ›å»ºï¼š")
        print("python create_test_split.py ./data --test_ratio 0.1")
    
    return True

def demo_model_check():
    """æ¼”ç¤ºæ¨¡åž‹æ£€æŸ¥åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æ¼”ç¤ºï¼šæ¨¡åž‹çŠ¶æ€æ£€æŸ¥")
    print("=" * 60)
    
    # æ£€æŸ¥å¯èƒ½çš„æ¨¡åž‹è·¯å¾„
    possible_paths = [
        Path("./data/output"),
        Path("./output"),
        Path("./models")
    ]
    
    model_found = False
    for model_path in possible_paths:
        print(f"\næ£€æŸ¥æ¨¡åž‹è·¯å¾„: {model_path}")
        
        if not model_path.exists():
            print("  âŒ è·¯å¾„ä¸å­˜åœ¨")
            continue
        
        # æ£€æŸ¥point_cloudç›®å½•
        point_cloud_dir = model_path / "point_cloud"
        if not point_cloud_dir.exists():
            print("  âŒ æœªæ‰¾åˆ° point_cloud ç›®å½•")
            continue
        
        # æŸ¥æ‰¾è¿­ä»£ç›®å½•
        iteration_dirs = [d for d in point_cloud_dir.iterdir() 
                         if d.is_dir() and d.name.startswith("iteration_")]
        
        if not iteration_dirs:
            print("  âŒ æœªæ‰¾åˆ°è¿­ä»£ç›®å½•")
            continue
        
        # æ£€æŸ¥æœ€æ–°è¿­ä»£
        latest_iteration = max(iteration_dirs, key=lambda x: int(x.name.split("_")[1]))
        ply_file = latest_iteration / "point_cloud.ply"
        
        if ply_file.exists():
            iteration_num = int(latest_iteration.name.split("_")[1])
            file_size = ply_file.stat().st_size / (1024*1024)  # MB
            print(f"  âœ… æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡åž‹")
            print(f"     è¿­ä»£æ¬¡æ•°: {iteration_num}")
            print(f"     æ¨¡åž‹æ–‡ä»¶: {ply_file}")
            print(f"     æ–‡ä»¶å¤§å°: {file_size:.1f} MB")
            model_found = True
            break
        else:
            print(f"  âŒ è¿­ä»£ {latest_iteration.name} ä¸­æœªæ‰¾åˆ° point_cloud.ply")
    
    if not model_found:
        print("\nâŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡åž‹")
        print("\nè¦è®­ç»ƒæ¨¡åž‹ï¼Œè¯·è¿è¡Œï¼š")
        print("python train.py -s ./data -m ./data/output --eval")
        print("\næ³¨æ„ï¼šè®­ç»ƒå¯èƒ½éœ€è¦å‡ ä¸ªå°æ—¶ï¼Œå–å†³äºŽæ‚¨çš„ç¡¬ä»¶é…ç½®")
    
    return model_found

def demo_evaluation_workflow():
    """æ¼”ç¤ºå®Œæ•´è¯„ä¼°æµç¨‹"""
    print("\n" + "=" * 60)
    print("æ¼”ç¤ºï¼šå®Œæ•´è¯„ä¼°æµç¨‹")
    print("=" * 60)
    
    print("\nå®Œæ•´çš„è¯„ä¼°æµç¨‹åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š")
    print("\n1. æµ‹è¯•é›†åˆ’åˆ†")
    print("   - ä»Žæ‰€æœ‰å›¾åƒä¸­é€‰æ‹©ä¸€éƒ¨åˆ†ä½œä¸ºæµ‹è¯•é›†")
    print("   - æ”¯æŒéšæœºã€å‡åŒ€ã€æ‰‹åŠ¨ä¸‰ç§é€‰æ‹©æ–¹å¼")
    print("   - ç”Ÿæˆ sparse/0/test.txt æ–‡ä»¶")
    
    print("\n2. æ¨¡åž‹è®­ç»ƒï¼ˆå¦‚æžœéœ€è¦ï¼‰")
    print("   - ä½¿ç”¨è®­ç»ƒé›†è®­ç»ƒ3D Gaussianæ¨¡åž‹")
    print("   - å¯ç”¨è¯„ä¼°æ¨¡å¼ä»¥æ”¯æŒæµ‹è¯•é›†è¯„ä¼°")
    print("   - ç”Ÿæˆ point_cloud.ply ç­‰æ¨¡åž‹æ–‡ä»¶")
    
    print("\n3. å®šé‡è¯„ä¼°")
    print("   - åœ¨æµ‹è¯•é›†ä¸Šæ¸²æŸ“å›¾åƒ")
    print("   - è®¡ç®—PSNRã€SSIMã€LPIPSæŒ‡æ ‡")
    print("   - ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š")
    
    print("\nå¯ç”¨çš„è„šæœ¬ï¼š")
    print("   - create_test_split.py: åˆ›å»ºæµ‹è¯•é›†åˆ’åˆ†")
    print("   - evaluate_test_set.py: è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡åž‹")
    print("   - run_evaluation.py: å®Œæ•´æµç¨‹è‡ªåŠ¨åŒ–")
    
    print("\nä½¿ç”¨ç¤ºä¾‹ï¼š")
    print("   # å¿«é€Ÿå¼€å§‹ï¼ˆæŽ¨èï¼‰")
    print("   python run_evaluation.py --data_path ./data")
    print("")
    print("   # åˆ†æ­¥æ‰§è¡Œ")
    print("   python create_test_split.py ./data --test_ratio 0.1")
    print("   python train.py -s ./data -m ./data/output --eval")
    print("   python evaluate_test_set.py --model_path ./data/output --source_path ./data")

def demo_metrics_explanation():
    """æ¼”ç¤ºè¯„ä¼°æŒ‡æ ‡è¯´æ˜Ž"""
    print("\n" + "=" * 60)
    print("æ¼”ç¤ºï¼šè¯„ä¼°æŒ‡æ ‡è¯´æ˜Ž")
    print("=" * 60)
    
    print("\nè¯„ä¼°æŒ‡æ ‡è¯¦è§£ï¼š")
    
    print("\nðŸ“Š PSNR (Peak Signal-to-Noise Ratio)")
    print("   - å³°å€¼ä¿¡å™ªæ¯”ï¼Œè¡¡é‡å›¾åƒé‡å»ºçš„åƒç´ çº§å‡†ç¡®æ€§")
    print("   - æ•°å€¼è¶Šé«˜è¶Šå¥½ï¼Œé€šå¸¸èŒƒå›´ï¼š20-40 dB")
    print("   - è®¡ç®—å…¬å¼åŸºäºŽå‡æ–¹è¯¯å·®(MSE)")
    
    print("\nðŸ“Š SSIM (Structural Similarity Index)")
    print("   - ç»“æž„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼Œè¡¡é‡å›¾åƒçš„ç»“æž„ç›¸ä¼¼æ€§")
    print("   - æ•°å€¼è¶Šé«˜è¶Šå¥½ï¼ŒèŒƒå›´ï¼š0-1")
    print("   - æ›´ç¬¦åˆäººçœ¼è§†è§‰æ„ŸçŸ¥")
    
    print("\nðŸ“Š LPIPS (Learned Perceptual Image Patch Similarity)")
    print("   - å­¦ä¹ æ„ŸçŸ¥å›¾åƒå—ç›¸ä¼¼æ€§")
    print("   - æ•°å€¼è¶Šä½Žè¶Šå¥½")
    print("   - åŸºäºŽæ·±åº¦ç½‘ç»œï¼Œæ›´å¥½åœ°åæ˜ äººçœ¼æ„ŸçŸ¥å·®å¼‚")
    
    print("\nå…¸åž‹çš„å¥½ç»“æžœèŒƒå›´ï¼š")
    print("   - PSNR: > 25 dB (ä¼˜ç§€: > 30 dB)")
    print("   - SSIM: > 0.8 (ä¼˜ç§€: > 0.9)")
    print("   - LPIPS: < 0.2 (ä¼˜ç§€: < 0.1)")

def main():
    print("3D Gaussian Splatting è¯„ä¼°å·¥å…·æ¼”ç¤º")
    print("" * 60)
    
    # æ£€æŸ¥å½“å‰ç›®å½•
    if not Path("./data").exists():
        print("é”™è¯¯ï¼šå½“å‰ç›®å½•ä¸‹æœªæ‰¾åˆ° data æ–‡ä»¶å¤¹")
        print("è¯·ç¡®ä¿åœ¨ gaussian-splatting é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
        return 1
    
    # è¿è¡Œæ¼”ç¤º
    demo_test_split()
    demo_model_check()
    demo_evaluation_workflow()
    demo_metrics_explanation()
    
    print("\n" + "=" * 60)
    print("æ¼”ç¤ºå®Œæˆ")
    print("=" * 60)
    print("\nä¸‹ä¸€æ­¥å»ºè®®ï¼š")
    print("1. å¦‚æžœè¿˜æ²¡æœ‰æµ‹è¯•é›†ï¼Œè¿è¡Œ: python create_test_split.py ./data")
    print("2. å¦‚æžœè¿˜æ²¡æœ‰è®­ç»ƒæ¨¡åž‹ï¼Œè¿è¡Œ: python train.py -s ./data -m ./data/output --eval")
    print("3. è¯„ä¼°æ¨¡åž‹æ€§èƒ½ï¼Œè¿è¡Œ: python evaluate_test_set.py --model_path ./data/output --source_path ./data")
    print("4. æˆ–è€…ä½¿ç”¨ä¸€é”®è„šæœ¬: python run_evaluation.py --data_path ./data")
    print("\nè¯¦ç»†è¯´æ˜Žè¯·å‚è€ƒ: EVALUATION_README.md")
    
    return 0

if __name__ == "__main__":
    exit(main())